{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is created to create appropriate data for the subject wise engagement analysis. It creates a seperate dataframe for raw metrics, unnormalized metrics and log-normalized metrics. This data will be used to create vizualizations in the web-app\n",
    "\n",
    "#### NOTE: At the end of notebook, we also have done similar analysis for overall discourse engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating metrics for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_to_description = {\n",
    "\"1\": \"likes_given\",\n",
    "\"2\": \"likes_received\",\n",
    "\"3\": \"bookmarked_post\",\n",
    "\"4\": \"created_new_topic\",\n",
    "\"5\": \"replied\",\n",
    "\"6\": \"received_response\",\n",
    "\"7\": \"user_was_mentioned\",\n",
    "\"9\": \"user's_post_quoted\",\n",
    "\"11\": \"user_edited_post\",\n",
    "\"12\": \"user_sent_private_message\",\n",
    "\"13\": \"recieved_a_private_message\",\n",
    "\"15\": \"solved_a_topic\",\n",
    "\"16\": \"user_was_assigned\",\n",
    "\"17\": \"linked\"\n",
    "}\n",
    "def create_raw_metrics_dataframe(df):\n",
    "    # Change the values in action_name column based on values of action_type and map it via the action_to_description dictionary. This is done to make the column_names more intuitive to understand.\n",
    "    df['action_type'] = df['action_type'].astype(str)\n",
    "    df['action_name'] = df['action_type'].map(action_to_description)\n",
    "    df = pd.crosstab(df[\"acting_username\"], df[\"action_name\"]) # Pivot table\n",
    "\n",
    "    columns_to_be_dropped = ['linked','received_response', \"user's_post_quoted\",\n",
    "        'user_edited_post', 'user_was_mentioned'] # dropping columns which are not required for analysis\n",
    "\n",
    "    df.drop(columns_to_be_dropped, axis=1, inplace=True, errors='ignore')\n",
    "    subject_dataframe = df.copy()\n",
    "    subject_dataframe['acting_username'] = subject_dataframe.index # Changing the index to a column\n",
    "    subject_dataframe = subject_dataframe[[\"acting_username\"]+[col for col in subject_dataframe.columns if col != 'acting_username']]  # Reordering the columns\n",
    "    subject_dataframe.index = range(0, len(subject_dataframe))\n",
    "    subject_dataframe.columns.name = None\n",
    "    return subject_dataframe # Returns raw metrics dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the weights to the relevant columns. This can be changed as per the requirement.\n",
    "weights_dict = { 'likes_given': 0.3, # 0.3\n",
    "                \"likes_received\": 0.8, # changed from 0.7\n",
    "                \"created_new_topic\": 0.5, # changed from 1.0\n",
    "                \"replied\": 0.7,\n",
    "                'solved_a_topic': 1\n",
    "}\n",
    "\n",
    "def create_raw_scores_dataframe(df):\n",
    "    columns_to_be_ignored = [\"initial_score\",'username','overall_topics_count_of_this_subject', 'normalised_score', 'z_score', \"acting_username\"] # this was directly taken from previous notebook. Some column names might seem irrelevant. Please ignore them.\n",
    "\n",
    "    df[\"initial_score\"] = sum(df[column]*weights_dict[column] for column in df.columns if column not in columns_to_be_ignored) # Initial score = sum(column_value*weight)\n",
    "\n",
    "    df[\"z_score\"] = round((df[\"initial_score\"] - df[\"initial_score\"].mean()) / df[\"initial_score\"].std(),2) # z_score rounded to 2 decimal places\n",
    "    return df.sort_values(by=\"z_score\",ascending=False)\n",
    "\n",
    "def create_log_normalized_scores_dataframe(df):\n",
    "    # Apply log normalization to the numerical features\n",
    "    numerical_features = df.select_dtypes(include=['number']).columns\n",
    "    log_normalized_dataframe = df.copy()\n",
    "    for feature in numerical_features:\n",
    "        log_normalized_dataframe[feature] = round(np.log1p(log_normalized_dataframe[feature]),3)\n",
    "    return log_normalized_dataframe.sort_values(by=\"z_score\",ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting category_ids of courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel files created with multiple sheets successfully!\n"
     ]
    }
   ],
   "source": [
    "# Get all the category_IDs\n",
    "df = pd.read_csv(\"all_category_ids.csv\")\n",
    "ids_for_demo = [22,25,27,28,29]\n",
    "df= df[df[\"category_id\"].isin(ids_for_demo)]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "for item in df.itertuples(name=None):\n",
    "    index = item[0]\n",
    "    category_id = item[1]\n",
    "    category_name = item[2]\n",
    "\n",
    "    user_actions_dataframe = pd.read_excel(f\"course_excel_data/{category_name}.xlsx\", sheet_name=\"user_actions_data\")\n",
    "\n",
    "    raw_metrics_dataframe = create_raw_metrics_dataframe(user_actions_dataframe)\n",
    "    raw_scores_dataframe = create_raw_scores_dataframe(raw_metrics_dataframe)\n",
    "    log_normalized_scores_dataframe = create_log_normalized_scores_dataframe(raw_metrics_dataframe)\n",
    "\n",
    "    # Use ExcelWriter in 'openpyxl' mode to append multiple sheets\n",
    "    file_path = f\"course_excel_data_t1_2024/{category_name}.xlsx\"\n",
    "    with pd.ExcelWriter(file_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"overlay\") as writer:\n",
    "        raw_metrics_dataframe.to_excel(writer, sheet_name=\"raw_metrics\", index=False)\n",
    "        raw_scores_dataframe.to_excel(writer, sheet_name=\"unnormalized_scores\", index=False)\n",
    "        log_normalized_scores_dataframe.to_excel(writer, sheet_name=\"log_normalized_scores\", index=False)\n",
    "\n",
    "print(\"Excel files created with multiple sheets successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of overall engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the weights to the relevant columns. This can be changed as per the requirement.\n",
    "weights_dict = { 'likes_given': 0.3, # 0.3\n",
    "                \"likes_received\": 0.8, # changed from 0.7\n",
    "                \"topics_viewed\": 0.4, # changed from 1.0\n",
    "                \"posts_read\": 0.7,\n",
    "                \"days_visited\": 0.7,\n",
    "                'solutions': 1,\n",
    "                \"cheers\": 0.3,\n",
    "}\n",
    "\n",
    "def create_raw_scores_dataframe_for_all_users(df):\n",
    "\n",
    "    df[\"initial_score\"] = sum(df[column]*weights_dict[column] for column in df.columns if column not in [\"user_id\"]) # Initial score = sum(column_value*weight)\n",
    "\n",
    "    df[\"z_score\"] = round((df[\"initial_score\"] - df[\"initial_score\"].mean()) / df[\"initial_score\"].std(),2) # z_score rounded to 2 decimal places\n",
    "    return df.sort_values(by=\"z_score\",ascending=False)\n",
    "\n",
    "def create_log_normalized_scores_dataframe(df):\n",
    "    # Apply log normalization to the numerical features\n",
    "    numerical_features = df.select_dtypes(include=['number']).columns\n",
    "    log_normalized_dataframe = df.copy()\n",
    "    for feature in numerical_features:\n",
    "        log_normalized_dataframe[feature] = round(np.log1p(log_normalized_dataframe[feature]),3)\n",
    "    return log_normalized_dataframe.sort_values(by=\"z_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_actions_dataframe = pd.read_excel(f\"course_excel_data_t1_2024/data_all_users.xlsx\", sheet_name=\"user_actions_data\")\n",
    "\n",
    "raw_scores_dataframe = create_raw_scores_dataframe_for_all_users(user_actions_dataframe)\n",
    "# log_normalized_scores_dataframe = create_log_normalized_scores_dataframe(raw_metrics_dataframe)\n",
    "\n",
    "# Use ExcelWriter in 'openpyxl' mode to append multiple sheets\n",
    "file_path = f\"course_excel_data_t1_2024/data_all_users.xlsx\"\n",
    "with pd.ExcelWriter(file_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"overlay\") as writer:\n",
    "    # raw_metrics_dataframe.to_excel(writer, sheet_name=\"raw_metrics\", index=False)\n",
    "    raw_scores_dataframe.to_excel(writer, sheet_name=\"unnormalized_scores\", index=False)\n",
    "    # log_normalized_scores_dataframe.to_excel(writer, sheet_name=\"log_normalized_scores\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
