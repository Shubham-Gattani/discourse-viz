{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is meant to create appropriate data for the subject wise engagement analysis. It creates a seperate dataframe for raw metrics, unnormalized metrics and log-normalized metrics. This data will be used to create vizualizations in the web-app\n",
    "\n",
    "### **NOTE: At the end of notebook, we also have done similar analysis for overall discourse engagement.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from global_functions_1 import sanitize_filepath # function to sanitize file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating metrics for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_to_description = {\n",
    "\"1\": \"likes_given\",\n",
    "\"2\": \"likes_received\",\n",
    "\"3\": \"bookmarked_post\",\n",
    "\"4\": \"created_new_topic\",\n",
    "\"5\": \"replied\",\n",
    "\"6\": \"received_response\",\n",
    "\"7\": \"user_was_mentioned\",\n",
    "\"9\": \"user's_post_quoted\",\n",
    "\"11\": \"user_edited_post\",\n",
    "\"12\": \"user_sent_private_message\",\n",
    "\"13\": \"recieved_a_private_message\",\n",
    "\"15\": \"solved_a_topic\",\n",
    "\"16\": \"user_was_assigned\",\n",
    "\"17\": \"linked\"\n",
    "}\n",
    "def create_raw_metrics_dataframe(df):\n",
    "    # Change the values in action_name column based on values of action_type and map it via the action_to_description dictionary. This is done to make the column_names more intuitive to understand.\n",
    "    subject_dataframe = df.copy()\n",
    "    subject_dataframe['action_type'] = subject_dataframe['action_type'].astype(str)\n",
    "    subject_dataframe['action_name'] = subject_dataframe['action_type'].map(action_to_description)\n",
    "    subject_dataframe = pd.crosstab(df[\"acting_username\"], subject_dataframe[\"action_name\"]) # Creating PIVOT table\n",
    "\n",
    "    columns_to_be_dropped = ['linked','received_response', \"user's_post_quoted\",\n",
    "        'user_edited_post', 'user_was_mentioned'] # dropping columns which are not required for analysis\n",
    "\n",
    "    subject_dataframe.drop(columns_to_be_dropped, axis=1, inplace=True, errors='ignore')\n",
    "    \n",
    "    subject_dataframe['acting_username'] = subject_dataframe.index # Changing the index to a column\n",
    "    subject_dataframe = subject_dataframe[[\"acting_username\"]+[col for col in subject_dataframe.columns if col != 'acting_username']]  # Reordering the columns\n",
    "    subject_dataframe.index = range(0, len(subject_dataframe))\n",
    "    subject_dataframe.columns.name = None\n",
    "    return subject_dataframe # Returns raw metrics dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the weights to the relevant columns. This can be changed as per the requirement.\n",
    "weights_dict = { 'likes_given': 0.3, # 0.3\n",
    "                \"likes_received\": 0.8, # changed from 0.7\n",
    "                \"created_new_topic\": 0.5, # changed from 1.0\n",
    "                \"replied\": 0.7,\n",
    "                'solved_a_topic': 10 # Highest weight\n",
    "}\n",
    "\n",
    "def create_raw_scores_dataframe(df): # unnormalised scores\n",
    "    df2 = pd.DataFrame(df.copy())\n",
    "    columns_to_be_ignored = [\"initial_score\",'username','overall_topics_count_of_this_subject', 'normalised_score', 'z_score', \"acting_username\"] # If some column names seem irrelevant, please ignore them.\n",
    "\n",
    "    df2[\"initial_score\"] = sum(df2[column]*weights_dict[column] for column in df2.columns if column not in columns_to_be_ignored) # Initial score = sum(column_value*weight)\n",
    "\n",
    "    df2[\"z_score\"] = round((df2[\"initial_score\"] - df2[\"initial_score\"].mean()) / df2[\"initial_score\"].std(),2) # z_score rounded to 2 decimal places\n",
    "    return df2.sort_values(by=\"z_score\",ascending=False)\n",
    "\n",
    "def create_log_normalized_scores_dataframe(df):\n",
    "    # Apply log normalization to the numerical features\n",
    "    numerical_features = list(weights_dict.keys())\n",
    "    # print(f\"numerical_features on which log_normalization is applied: {numerical_features}\")\n",
    "    log_normalized_dataframe = df.copy()\n",
    "    for feature in numerical_features:\n",
    "        try:\n",
    "            log_normalized_dataframe[feature] = round(np.log1p(log_normalized_dataframe[feature]),3)\n",
    "        except Exception as e:\n",
    "            print(f\"\\n********Error in log normalization for feature {feature}: {e}\\n********\\n\")\n",
    "            numerical_features.remove(feature) # Remove the feature from the list if log normalization fails\n",
    "            continue\n",
    "    \n",
    "    log_normalized_dataframe[\"initial_score\"] = log_normalized_dataframe[numerical_features].sum(axis=1)\n",
    "    log_normalized_dataframe[\"z_score\"] = round(\n",
    "        (log_normalized_dataframe[\"initial_score\"] - log_normalized_dataframe[\"initial_score\"].mean()) / log_normalized_dataframe[\"initial_score\"].std(),2)\n",
    "    return log_normalized_dataframe.sort_values(by=\"z_score\",ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>Mathematics for Data Science I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>Statistics for Data Science I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>Computational Thinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>English I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>English II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id                            name\n",
       "0           18  Mathematics for Data Science I\n",
       "1           19   Statistics for Data Science I\n",
       "2           20          Computational Thinking\n",
       "3           21                       English I\n",
       "4           22                      English II"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the category_IDs\n",
    "all_category_ids = pd.read_csv(\"../data/all_category_ids.csv\")\n",
    "all_category_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Mathematics_for_Data_Science_I for term t1_2025\n",
      "Processing Statistics_for_Data_Science_I for term t1_2025\n",
      "Processing Computational_Thinking for term t1_2025\n",
      "Processing English_I for term t1_2025\n",
      "Processing English_II for term t1_2025\n",
      "Processing Mathematics_for_Data_Science_II for term t1_2025\n",
      "Processing Statistics_for_Data_Science_II for term t1_2025\n",
      "Processing Programming_in_Python for term t1_2025\n",
      "Processing Programming,_Data_Structures_and_Algorithms for term t1_2025\n",
      "Processing Database_Management_Systems for term t1_2025\n",
      "Processing Machine_Learning_Foundations for term t1_2025\n",
      "Processing Modern_Application_Development_I for term t1_2025\n",
      "Processing Business_Data_Management for term t1_2025\n",
      "Processing Machine_Learning_Techniques for term t1_2025\n",
      "Processing Machine_Learning_Practice for term t1_2025\n",
      "Processing Tools_in_Data_Science for term t1_2025\n",
      "Processing Business_Analytics for term t1_2025\n",
      "Processing System_Commands for term t1_2025\n",
      "Processing Modern_Application_Development_II for term t1_2025\n",
      "Processing Programming_Concepts_using_Java for term t1_2025\n",
      "Processing Project_for_MAD1 for term t1_2025\n",
      "Processing Project_for_MAD2 for term t1_2025\n",
      "Processing Project_for_BDM for term t1_2025\n",
      "Processing Project_for_MLP for term t1_2025\n",
      "Processing Deep_Learning for term t1_2025\n",
      "Processing AI__Search_Methods_for_Problem_Solving for term t1_2025\n",
      "Processing Software_Testing for term t1_2025\n",
      "Processing Software_Engineering for term t1_2025\n",
      "Processing Strategies_for_Professional_Growth for term t1_2025\n",
      "Processing Industry_4.0 for term t1_2025\n",
      "Processing Design_Thinking_for_Data_Driven_App_Development for term t1_2025\n",
      "Making empty dataframes for Design_Thinking_for_Data_Driven_App_Development as it has <= 0 rows\n",
      "Processing Speech_Technology for term t1_2025\n",
      "Making empty dataframes for Speech_Technology as it has <= 0 rows\n",
      "Processing Privacy_&_Security_in_Online_Social_Media for term t1_2025\n",
      "Making empty dataframes for Privacy_&_Security_in_Online_Social_Media as it has <= 0 rows\n",
      "Processing Algorithmic_Thinking_in_Bioinformatics for term t1_2025\n",
      "Making empty dataframes for Algorithmic_Thinking_in_Bioinformatics as it has <= 48 rows\n",
      "Processing Data_Visualization_Design for term t1_2025\n",
      "Making empty dataframes for Data_Visualization_Design as it has <= 24 rows\n",
      "Processing Linear_Statistical_Models for term t1_2025\n",
      "Making empty dataframes for Linear_Statistical_Models as it has <= 27 rows\n",
      "Processing Market_Research for term t1_2025\n",
      "Making empty dataframes for Market_Research as it has <= 0 rows\n",
      "Processing Introduction_to_Big_Data for term t1_2025\n",
      "Making empty dataframes for Introduction_to_Big_Data as it has <= 50 rows\n",
      "Processing Financial_Forensics for term t1_2025\n",
      "Making empty dataframes for Financial_Forensics as it has <= 60 rows\n",
      "Processing Big_Data_and_Biological_Networks for term t1_2025\n",
      "Processing Advanced_Algorithms for term t1_2025\n",
      "Making empty dataframes for Advanced_Algorithms as it has <= 0 rows\n",
      "Processing Special_topics_in_ML_(Reinforcement_Learning) for term t1_2025\n",
      "Processing Statistical_Computing for term t1_2025\n",
      "Making empty dataframes for Statistical_Computing as it has <= 0 rows\n",
      "Processing Programming_in_C for term t1_2025\n",
      "Processing Mathematical_Thinking for term t1_2025\n",
      "Making empty dataframes for Mathematical_Thinking as it has <= 13 rows\n",
      "Processing Computer_System_Design for term t1_2025\n",
      "Making empty dataframes for Computer_System_Design as it has <= 1 rows\n",
      "Processing Operating_Systems for term t1_2025\n",
      "Making empty dataframes for Operating_Systems as it has <= 50 rows\n",
      "Processing Deep_Learning_for_Computer_Vision for term t1_2025\n",
      "Making empty dataframes for Deep_Learning_for_Computer_Vision as it has <= 24 rows\n",
      "Processing Large_Language_Models for term t1_2025\n",
      "Processing Managerial_Economics for term t1_2025\n",
      "Processing Game_Theory_and_Strategy for term t1_2025\n",
      "Making empty dataframes for Game_Theory_and_Strategy as it has <= 1 rows\n",
      "Processing Corporate_Finance for term t1_2025\n",
      "\n",
      "********Error in log normalization for feature solved_a_topic: 'solved_a_topic'\n",
      "********\n",
      "\n",
      "Processing Deep_Learning_Practice for term t1_2025\n",
      "Processing Introduction_to_Natural_Language_Processing for term t1_2025\n",
      "Making empty dataframes for Introduction_to_Natural_Language_Processing as it has <= 40 rows\n",
      "Processing Mathematics_for_Data_Science_I for term t2_2024\n",
      "Processing Statistics_for_Data_Science_I for term t2_2024\n",
      "Processing Computational_Thinking for term t2_2024\n",
      "Processing English_I for term t2_2024\n",
      "Processing English_II for term t2_2024\n",
      "Processing Mathematics_for_Data_Science_II for term t2_2024\n",
      "Processing Statistics_for_Data_Science_II for term t2_2024\n",
      "Processing Programming_in_Python for term t2_2024\n",
      "Processing Programming,_Data_Structures_and_Algorithms for term t2_2024\n",
      "Processing Database_Management_Systems for term t2_2024\n",
      "Processing Machine_Learning_Foundations for term t2_2024\n",
      "Processing Modern_Application_Development_I for term t2_2024\n",
      "Processing Business_Data_Management for term t2_2024\n",
      "Processing Machine_Learning_Techniques for term t2_2024\n",
      "Processing Machine_Learning_Practice for term t2_2024\n",
      "Processing Tools_in_Data_Science for term t2_2024\n",
      "Processing Business_Analytics for term t2_2024\n",
      "Processing System_Commands for term t2_2024\n",
      "Processing Modern_Application_Development_II for term t2_2024\n",
      "Processing Programming_Concepts_using_Java for term t2_2024\n",
      "Processing Project_for_MAD1 for term t2_2024\n",
      "Processing Project_for_MAD2 for term t2_2024\n",
      "Processing Project_for_BDM for term t2_2024\n",
      "Processing Project_for_MLP for term t2_2024\n",
      "Processing Deep_Learning for term t2_2024\n",
      "Processing AI__Search_Methods_for_Problem_Solving for term t2_2024\n",
      "Processing Software_Testing for term t2_2024\n",
      "Processing Software_Engineering for term t2_2024\n",
      "Processing Strategies_for_Professional_Growth for term t2_2024\n",
      "Processing Industry_4.0 for term t2_2024\n",
      "Processing Design_Thinking_for_Data_Driven_App_Development for term t2_2024\n",
      "Making empty dataframes for Design_Thinking_for_Data_Driven_App_Development as it has <= 0 rows\n",
      "Processing Speech_Technology for term t2_2024\n",
      "Making empty dataframes for Speech_Technology as it has <= 0 rows\n",
      "Processing Privacy_&_Security_in_Online_Social_Media for term t2_2024\n",
      "Making empty dataframes for Privacy_&_Security_in_Online_Social_Media as it has <= 0 rows\n",
      "Processing Algorithmic_Thinking_in_Bioinformatics for term t2_2024\n",
      "Processing Data_Visualization_Design for term t2_2024\n",
      "Making empty dataframes for Data_Visualization_Design as it has <= 37 rows\n",
      "Processing Linear_Statistical_Models for term t2_2024\n",
      "Making empty dataframes for Linear_Statistical_Models as it has <= 32 rows\n",
      "Processing Market_Research for term t2_2024\n",
      "Making empty dataframes for Market_Research as it has <= 0 rows\n",
      "Processing Introduction_to_Big_Data for term t2_2024\n",
      "Processing Financial_Forensics for term t2_2024\n",
      "Processing Big_Data_and_Biological_Networks for term t2_2024\n",
      "Making empty dataframes for Big_Data_and_Biological_Networks as it has <= 21 rows\n",
      "Processing Advanced_Algorithms for term t2_2024\n",
      "Processing Special_topics_in_ML_(Reinforcement_Learning) for term t2_2024\n",
      "Processing Statistical_Computing for term t2_2024\n",
      "Making empty dataframes for Statistical_Computing as it has <= 0 rows\n",
      "Processing Programming_in_C for term t2_2024\n",
      "Processing Mathematical_Thinking for term t2_2024\n",
      "Making empty dataframes for Mathematical_Thinking as it has <= 54 rows\n",
      "Processing Computer_System_Design for term t2_2024\n",
      "Making empty dataframes for Computer_System_Design as it has <= 51 rows\n",
      "Processing Operating_Systems for term t2_2024\n",
      "Processing Deep_Learning_for_Computer_Vision for term t2_2024\n",
      "Processing Large_Language_Models for term t2_2024\n",
      "Processing Managerial_Economics for term t2_2024\n",
      "Processing Game_Theory_and_Strategy for term t2_2024\n",
      "Making empty dataframes for Game_Theory_and_Strategy as it has <= 13 rows\n",
      "Processing Corporate_Finance for term t2_2024\n",
      "Making empty dataframes for Corporate_Finance as it has <= 0 rows\n",
      "Processing Deep_Learning_Practice for term t2_2024\n",
      "Making empty dataframes for Deep_Learning_Practice as it has <= 0 rows\n",
      "Processing Introduction_to_Natural_Language_Processing for term t2_2024\n",
      "Making empty dataframes for Introduction_to_Natural_Language_Processing as it has <= 0 rows\n",
      "Processing Mathematics_for_Data_Science_I for term t3_2024\n",
      "Processing Statistics_for_Data_Science_I for term t3_2024\n",
      "Processing Computational_Thinking for term t3_2024\n",
      "Processing English_I for term t3_2024\n",
      "Processing English_II for term t3_2024\n",
      "Processing Mathematics_for_Data_Science_II for term t3_2024\n",
      "Processing Statistics_for_Data_Science_II for term t3_2024\n",
      "Processing Programming_in_Python for term t3_2024\n",
      "Processing Programming,_Data_Structures_and_Algorithms for term t3_2024\n",
      "Processing Database_Management_Systems for term t3_2024\n",
      "Processing Machine_Learning_Foundations for term t3_2024\n",
      "Processing Modern_Application_Development_I for term t3_2024\n",
      "Processing Business_Data_Management for term t3_2024\n",
      "Processing Machine_Learning_Techniques for term t3_2024\n",
      "Processing Machine_Learning_Practice for term t3_2024\n",
      "Processing Tools_in_Data_Science for term t3_2024\n",
      "Processing Business_Analytics for term t3_2024\n",
      "Processing System_Commands for term t3_2024\n",
      "Processing Modern_Application_Development_II for term t3_2024\n",
      "Processing Programming_Concepts_using_Java for term t3_2024\n",
      "Processing Project_for_MAD1 for term t3_2024\n",
      "Processing Project_for_MAD2 for term t3_2024\n",
      "Processing Project_for_BDM for term t3_2024\n",
      "Processing Project_for_MLP for term t3_2024\n",
      "Processing Deep_Learning for term t3_2024\n",
      "Processing AI__Search_Methods_for_Problem_Solving for term t3_2024\n",
      "Processing Software_Testing for term t3_2024\n",
      "Processing Software_Engineering for term t3_2024\n",
      "Processing Strategies_for_Professional_Growth for term t3_2024\n",
      "Processing Industry_4.0 for term t3_2024\n",
      "\n",
      "********Error in log normalization for feature solved_a_topic: 'solved_a_topic'\n",
      "********\n",
      "\n",
      "Processing Design_Thinking_for_Data_Driven_App_Development for term t3_2024\n",
      "Processing Speech_Technology for term t3_2024\n",
      "Making empty dataframes for Speech_Technology as it has <= 0 rows\n",
      "Processing Privacy_&_Security_in_Online_Social_Media for term t3_2024\n",
      "Making empty dataframes for Privacy_&_Security_in_Online_Social_Media as it has <= 56 rows\n",
      "Processing Algorithmic_Thinking_in_Bioinformatics for term t3_2024\n",
      "Making empty dataframes for Algorithmic_Thinking_in_Bioinformatics as it has <= 46 rows\n",
      "Processing Data_Visualization_Design for term t3_2024\n",
      "Making empty dataframes for Data_Visualization_Design as it has <= 0 rows\n",
      "Processing Linear_Statistical_Models for term t3_2024\n",
      "Making empty dataframes for Linear_Statistical_Models as it has <= 0 rows\n",
      "Processing Market_Research for term t3_2024\n",
      "Making empty dataframes for Market_Research as it has <= 53 rows\n",
      "Processing Introduction_to_Big_Data for term t3_2024\n",
      "Processing Financial_Forensics for term t3_2024\n",
      "Processing Big_Data_and_Biological_Networks for term t3_2024\n",
      "Making empty dataframes for Big_Data_and_Biological_Networks as it has <= 0 rows\n",
      "Processing Advanced_Algorithms for term t3_2024\n",
      "Processing Special_topics_in_ML_(Reinforcement_Learning) for term t3_2024\n",
      "Processing Statistical_Computing for term t3_2024\n",
      "Making empty dataframes for Statistical_Computing as it has <= 16 rows\n",
      "Processing Programming_in_C for term t3_2024\n",
      "Processing Mathematical_Thinking for term t3_2024\n",
      "Making empty dataframes for Mathematical_Thinking as it has <= 0 rows\n",
      "Processing Computer_System_Design for term t3_2024\n",
      "Processing Operating_Systems for term t3_2024\n",
      "Making empty dataframes for Operating_Systems as it has <= 24 rows\n",
      "Processing Deep_Learning_for_Computer_Vision for term t3_2024\n",
      "Making empty dataframes for Deep_Learning_for_Computer_Vision as it has <= 43 rows\n",
      "Processing Large_Language_Models for term t3_2024\n",
      "Processing Managerial_Economics for term t3_2024\n",
      "Making empty dataframes for Managerial_Economics as it has <= 8 rows\n",
      "Processing Game_Theory_and_Strategy for term t3_2024\n",
      "Making empty dataframes for Game_Theory_and_Strategy as it has <= 32 rows\n",
      "Processing Corporate_Finance for term t3_2024\n",
      "\n",
      "********Error in log normalization for feature solved_a_topic: 'solved_a_topic'\n",
      "********\n",
      "\n",
      "Processing Deep_Learning_Practice for term t3_2024\n",
      "Processing Introduction_to_Natural_Language_Processing for term t3_2024\n"
     ]
    }
   ],
   "source": [
    "terms_folder = \"../data/course_specific_data\"\n",
    "for term in list(os.listdir(terms_folder))[1:]:\n",
    "    for item in all_category_ids.itertuples(name=None):\n",
    "        # try:\n",
    "            # Now process the data for each course in the term\n",
    "            category_id = item[1]\n",
    "            category_name = sanitize_filepath(item[2])\n",
    "            print(f\"Processing {category_name} for term {term}\")\n",
    "            \n",
    "            # Read the user_actions_data for the course\n",
    "            user_actions_dataframe = pd.read_excel(f\"../data/course_specific_data/{term}/{category_name}.xlsx\", sheet_name=\"user_actions_data\")\n",
    "\n",
    "            # If some course is not offered in a term, the user_action_dataframe can be empty or it can have very less rows (because of some overlapping days in the term). We will process the data iff it has more than 75 rows.\n",
    "            if (not user_actions_dataframe.empty) and (len(user_actions_dataframe) > 75):          \n",
    "                raw_metrics_dataframe = create_raw_metrics_dataframe(user_actions_dataframe)\n",
    "                raw_scores_dataframe = create_raw_scores_dataframe(raw_metrics_dataframe) # unnormalised scores\n",
    "                log_normalized_scores_dataframe = create_log_normalized_scores_dataframe(raw_scores_dataframe) # log normalized scores\n",
    "            else:\n",
    "                print(f\"Making empty dataframes for {category_name} as it has <= {len(user_actions_dataframe)} rows\")\n",
    "                raw_metrics_dataframe, raw_scores_dataframe, log_normalized_scores_dataframe = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "            \n",
    "\n",
    "            scores_data_path = f\"../data/scores/{term}\" # The scores for each course will be stored for each term in a separate folder.\n",
    "            os.makedirs(scores_data_path, exist_ok=True)\n",
    "            file_path = f\"{scores_data_path}/{category_name}.xlsx\"\n",
    "\n",
    "            # Use ExcelWriter in 'openpyxl' mode to append multiple sheets\n",
    "            with pd.ExcelWriter(file_path, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "                raw_metrics_dataframe.to_excel(writer, sheet_name=\"raw_metrics\", index=False)\n",
    "                raw_scores_dataframe.to_excel(writer, sheet_name=\"unnormalized_scores\", index=False)\n",
    "                log_normalized_scores_dataframe.to_excel(writer, sheet_name=\"log_normalized_scores\", index=False)\n",
    "        # except Exception as e:\n",
    "        #     print(f\"Error: {e} for category_name: {category_name}\")\n",
    "        #     continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of \"all users engagement\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the weights to the relevant columns. This can be changed as per the requirement.\n",
    "weights_dict = { 'likes_given': 0.4, # likes_given is also important\n",
    "                \"likes_received\": 0.8,\n",
    "                \"topics_created\": 0.4,\n",
    "                \"posts_created\": 0.7,\n",
    "                \"days_visited\": 0.3, # decreased weightage because it is a very common action\n",
    "                'solutions': 10,\n",
    "                \"cheers\": 0, # discard cheers as it's meaning is not clear.\n",
    "}\n",
    "\n",
    "def create_raw_scores_dataframe_for_all_users(df_original):\n",
    "    df = df_original.copy()\n",
    "    df[\"initial_score\"] = sum(df[column]*weights_dict[column] for column in df.columns if column not in [\"user_id\"]) # Initial score = sum(column_value*weight)\n",
    "\n",
    "    df[\"z_score\"] = round((df[\"initial_score\"] - df[\"initial_score\"].mean()) / df[\"initial_score\"].std(),2) # z_score rounded to 2 decimal places\n",
    "    return df.sort_values(by=\"z_score\",ascending=False)\n",
    "\n",
    "def create_log_normalized_scores_dataframe(df):\n",
    "    # Apply log normalization to the numerical features\n",
    "    numerical_features = list(weights_dict.keys())\n",
    "    # print(f\"numerical_features on which log_normalization is applied: {numerical_features}\")\n",
    "    log_normalized_dataframe = df.copy()\n",
    "    for feature in numerical_features:\n",
    "        log_normalized_dataframe[feature] = round(np.log1p(log_normalized_dataframe[feature]),3)\n",
    "    \n",
    "    log_normalized_dataframe[\"initial_score\"] = log_normalized_dataframe[numerical_features].sum(axis=1)\n",
    "    log_normalized_dataframe[\"z_score\"] = round((log_normalized_dataframe[\"initial_score\"] - log_normalized_dataframe[\"initial_score\"].mean()) / log_normalized_dataframe[\"initial_score\"].std(),2)\n",
    "    return log_normalized_dataframe.sort_values(by=\"z_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/scores/overall_scores\\t1_2024\n",
      "../data/scores/overall_scores\\t1_2025\n",
      "../data/scores/overall_scores\\t2_2024\n",
      "../data/scores/overall_scores\\t3_2024\n"
     ]
    }
   ],
   "source": [
    "overall_scores_folder = \"../data/scores/overall_scores\" # This will contain the scores of users which will reflect their overall discourse engagement in that particular term\n",
    "os.makedirs(overall_scores_folder, exist_ok=True)\n",
    "\n",
    "raw_data_for_all_users = \"../data/overall_data_all_users\"\n",
    "\n",
    "for file in os.listdir(raw_data_for_all_users):\n",
    "    term = file.split(\"data_all_users_\")[1].removesuffix(\".xlsx\")\n",
    "    file_path = os.path.join(raw_data_for_all_users,file)\n",
    "    user_actions_dataframe = pd.read_excel(file_path, sheet_name=\"user_actions_data\").drop(columns=[\"posts_read\",\"topics_viewed\",\"cheers\"])\n",
    "\n",
    "    raw_scores_dataframe = create_raw_scores_dataframe_for_all_users(user_actions_dataframe)\n",
    "    # log_normalized_scores_dataframe = create_log_normalized_scores_dataframe(raw_metrics_dataframe)\n",
    "    final_metrics_path = os.path.join(overall_scores_folder,term)\n",
    "    print(final_metrics_path)\n",
    "    with pd.ExcelWriter(f\"{final_metrics_path}.xlsx\", engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "        # raw_metrics_dataframe.to_excel(writer, sheet_name=\"raw_metrics\", index=False)\n",
    "        raw_scores_dataframe.to_excel(writer, sheet_name=\"unnormalized_scores\", index=False)\n",
    "        # log_normalized_scores_dataframe.to_excel(writer, sheet_name=\"log_normalized_scores\", index=False)\n",
    "        # We have not taken log normalized scores for all users as it is not required for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING/EXPLORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acting_username</th>\n",
       "      <th>created_new_topic</th>\n",
       "      <th>likes_given</th>\n",
       "      <th>likes_received</th>\n",
       "      <th>replied</th>\n",
       "      <th>solved_a_topic</th>\n",
       "      <th>initial_score</th>\n",
       "      <th>z_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teza</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>29.7</td>\n",
       "      <td>6.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23f2002361</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23f1000917</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23f3001021</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23f3003974</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  acting_username  created_new_topic  likes_given  likes_received  replied  \\\n",
       "0            teza                  0            0              10       21   \n",
       "1      23f2002361                  7            1               3        9   \n",
       "2      23f1000917                  2            2               6        8   \n",
       "3      23f3001021                  2            2               3        5   \n",
       "4      23f3003974                  1            3               3        2   \n",
       "\n",
       "   solved_a_topic  initial_score  z_score  \n",
       "0               7           29.7     6.64  \n",
       "1               0           12.5     2.52  \n",
       "2               0           12.0     2.40  \n",
       "3               1            8.5     1.57  \n",
       "4               0            5.2     0.78  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_excel(\"course_excel_data_t1_2024/English II.xlsx\", sheet_name=\"unnormalized_scores\").head()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acting_username</th>\n",
       "      <th>created_new_topic</th>\n",
       "      <th>likes_given</th>\n",
       "      <th>likes_received</th>\n",
       "      <th>replied</th>\n",
       "      <th>solved_a_topic</th>\n",
       "      <th>initial_score</th>\n",
       "      <th>z_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teza</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.398</td>\n",
       "      <td>3.091</td>\n",
       "      <td>2.079</td>\n",
       "      <td>7.568</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23f2002361</td>\n",
       "      <td>2.079</td>\n",
       "      <td>0.693</td>\n",
       "      <td>1.386</td>\n",
       "      <td>2.303</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.461</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23f1000917</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.946</td>\n",
       "      <td>2.197</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.341</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23f3001021</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.386</td>\n",
       "      <td>1.792</td>\n",
       "      <td>0.693</td>\n",
       "      <td>6.069</td>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23f3003974</td>\n",
       "      <td>0.693</td>\n",
       "      <td>1.386</td>\n",
       "      <td>1.386</td>\n",
       "      <td>1.099</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.564</td>\n",
       "      <td>-1.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  acting_username  created_new_topic  likes_given  likes_received  replied  \\\n",
       "0            teza              0.000        0.000           2.398    3.091   \n",
       "1      23f2002361              2.079        0.693           1.386    2.303   \n",
       "2      23f1000917              1.099        1.099           1.946    2.197   \n",
       "3      23f3001021              1.099        1.099           1.386    1.792   \n",
       "4      23f3003974              0.693        1.386           1.386    1.099   \n",
       "\n",
       "   solved_a_topic  initial_score  z_score  \n",
       "0           2.079          7.568     1.27  \n",
       "1           0.000          6.461     0.24  \n",
       "2           0.000          6.341     0.13  \n",
       "3           0.693          6.069    -0.12  \n",
       "4           0.000          4.564    -1.52  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create_log_normalized_scores_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/course_specific_data/t1_2024/Advanced_Algorithms.xlsx\"\n",
    "df = pd.read_excel(path, sheet_name=\"user_actions_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.empty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
