{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is created to create appropriate data for the subject wise engagement analysis. It creates a seperate dataframe for raw metrics, unnormalized metrics and log-normalized metrics. This data will be used to create vizualizations in the web-app\n",
    "\n",
    "### **NOTE: At the end of notebook, we also have done similar analysis for overall discourse engagement.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating metrics for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_to_description = {\n",
    "\"1\": \"likes_given\",\n",
    "\"2\": \"likes_received\",\n",
    "\"3\": \"bookmarked_post\",\n",
    "\"4\": \"created_new_topic\",\n",
    "\"5\": \"replied\",\n",
    "\"6\": \"received_response\",\n",
    "\"7\": \"user_was_mentioned\",\n",
    "\"9\": \"user's_post_quoted\",\n",
    "\"11\": \"user_edited_post\",\n",
    "\"12\": \"user_sent_private_message\",\n",
    "\"13\": \"recieved_a_private_message\",\n",
    "\"15\": \"solved_a_topic\",\n",
    "\"16\": \"user_was_assigned\",\n",
    "\"17\": \"linked\"\n",
    "}\n",
    "def create_raw_metrics_dataframe(df):\n",
    "    # Change the values in action_name column based on values of action_type and map it via the action_to_description dictionary. This is done to make the column_names more intuitive to understand.\n",
    "    subject_dataframe = df.copy()\n",
    "    subject_dataframe['action_type'] = subject_dataframe['action_type'].astype(str)\n",
    "    subject_dataframe['action_name'] = subject_dataframe['action_type'].map(action_to_description)\n",
    "    subject_dataframe = pd.crosstab(df[\"acting_username\"], subject_dataframe[\"action_name\"]) # Pivot table\n",
    "\n",
    "    columns_to_be_dropped = ['linked','received_response', \"user's_post_quoted\",\n",
    "        'user_edited_post', 'user_was_mentioned'] # dropping columns which are not required for analysis\n",
    "\n",
    "    subject_dataframe.drop(columns_to_be_dropped, axis=1, inplace=True, errors='ignore')\n",
    "    \n",
    "    subject_dataframe['acting_username'] = subject_dataframe.index # Changing the index to a column\n",
    "    subject_dataframe = subject_dataframe[[\"acting_username\"]+[col for col in subject_dataframe.columns if col != 'acting_username']]  # Reordering the columns\n",
    "    subject_dataframe.index = range(0, len(subject_dataframe))\n",
    "    subject_dataframe.columns.name = None\n",
    "    return subject_dataframe # Returns raw metrics dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the weights to the relevant columns. This can be changed as per the requirement.\n",
    "weights_dict = { 'likes_given': 0.3, # 0.3\n",
    "                \"likes_received\": 0.8, # changed from 0.7\n",
    "                \"created_new_topic\": 0.5, # changed from 1.0\n",
    "                \"replied\": 0.7,\n",
    "                'solved_a_topic': 1 # Highest weight\n",
    "}\n",
    "\n",
    "def create_raw_scores_dataframe(df): # unnormalised scores\n",
    "    df2 = pd.DataFrame(df.copy())\n",
    "    columns_to_be_ignored = [\"initial_score\",'username','overall_topics_count_of_this_subject', 'normalised_score', 'z_score', \"acting_username\"] # this was directly taken from previous notebook. Some column names might seem irrelevant. Please ignore them.\n",
    "\n",
    "    df2[\"initial_score\"] = sum(df2[column]*weights_dict[column] for column in df2.columns if column not in columns_to_be_ignored) # Initial score = sum(column_value*weight)\n",
    "\n",
    "    df2[\"z_score\"] = round((df2[\"initial_score\"] - df2[\"initial_score\"].mean()) / df2[\"initial_score\"].std(),2) # z_score rounded to 2 decimal places\n",
    "    return df2.sort_values(by=\"z_score\",ascending=False)\n",
    "\n",
    "def create_log_normalized_scores_dataframe(df):\n",
    "    # Apply log normalization to the numerical features\n",
    "    numerical_features = list(weights_dict.keys())\n",
    "    # print(f\"numerical_features on which log_normalization is applied: {numerical_features}\")\n",
    "    log_normalized_dataframe = df.copy()\n",
    "    for feature in numerical_features:\n",
    "        log_normalized_dataframe[feature] = round(np.log1p(log_normalized_dataframe[feature]),3)\n",
    "    \n",
    "    # log_normalized_dataframe[\"initial_score\"] = sum(log_normalized_dataframe[numerical_features])\n",
    "    log_normalized_dataframe[\"initial_score\"] = log_normalized_dataframe[numerical_features].sum(axis=1)\n",
    "    log_normalized_dataframe[\"z_score\"] = round((log_normalized_dataframe[\"initial_score\"] - log_normalized_dataframe[\"initial_score\"].mean()) / log_normalized_dataframe[\"initial_score\"].std(),2)\n",
    "    return log_normalized_dataframe.sort_values(by=\"z_score\",ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting category_ids of courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel files created with multiple sheets successfully!\n"
     ]
    }
   ],
   "source": [
    "# Get all the category_IDs\n",
    "df = pd.read_csv(\"all_category_ids.csv\")\n",
    "ids_for_demo = [22,25,27,28,29]\n",
    "df= df[df[\"category_id\"].isin(ids_for_demo)]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "for item in df.itertuples(name=None):\n",
    "    index = item[0]\n",
    "    category_id = item[1]\n",
    "    category_name = item[2]\n",
    "\n",
    "    user_actions_dataframe = pd.read_excel(f\"course_excel_data_t1_2024/{category_name}.xlsx\", sheet_name=\"user_actions_data\")\n",
    "\n",
    "    raw_metrics_dataframe = create_raw_metrics_dataframe(user_actions_dataframe)\n",
    "    raw_scores_dataframe = create_raw_scores_dataframe(raw_metrics_dataframe) # unnormalised scores\n",
    "    log_normalized_scores_dataframe = create_log_normalized_scores_dataframe(raw_scores_dataframe) # log normalized scores\n",
    "\n",
    "    # Use ExcelWriter in 'openpyxl' mode to append multiple sheets\n",
    "    file_path = f\"course_excel_data_t1_2024/{category_name}.xlsx\"\n",
    "    with pd.ExcelWriter(file_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"overlay\") as writer:\n",
    "        raw_metrics_dataframe.to_excel(writer, sheet_name=\"raw_metrics\", index=False)\n",
    "        raw_scores_dataframe.to_excel(writer, sheet_name=\"unnormalized_scores\", index=False)\n",
    "        log_normalized_scores_dataframe.to_excel(writer, sheet_name=\"log_normalized_scores\", index=False)\n",
    "\n",
    "print(\"Excel files created with multiple sheets successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of \"all users engagement\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the weights to the relevant columns. This can be changed as per the requirement.\n",
    "weights_dict = { 'likes_given': 0.4, # likes_given is also important\n",
    "                \"likes_received\": 0.8,\n",
    "                \"topics_created\": 0.4,\n",
    "                \"posts_created\": 0.7,\n",
    "                \"days_visited\": 0.3, # decreased weightage because it is a very common action\n",
    "                'solutions': 1,\n",
    "                \"cheers\": 0, # discard cheers as it's meaning is not clear.\n",
    "}\n",
    "\n",
    "def create_raw_scores_dataframe_for_all_users(df_original):\n",
    "    df = df_original.copy()\n",
    "    df[\"initial_score\"] = sum(df[column]*weights_dict[column] for column in df.columns if column not in [\"user_id\"]) # Initial score = sum(column_value*weight)\n",
    "\n",
    "    df[\"z_score\"] = round((df[\"initial_score\"] - df[\"initial_score\"].mean()) / df[\"initial_score\"].std(),2) # z_score rounded to 2 decimal places\n",
    "    return df.sort_values(by=\"z_score\",ascending=False)\n",
    "\n",
    "def create_log_normalized_scores_dataframe(df):\n",
    "    # Apply log normalization to the numerical features\n",
    "    numerical_features = list(weights_dict.keys())\n",
    "    # print(f\"numerical_features on which log_normalization is applied: {numerical_features}\")\n",
    "    log_normalized_dataframe = df.copy()\n",
    "    for feature in numerical_features:\n",
    "        log_normalized_dataframe[feature] = round(np.log1p(log_normalized_dataframe[feature]),3)\n",
    "    \n",
    "    log_normalized_dataframe[\"initial_score\"] = log_normalized_dataframe[numerical_features].sum(axis=1)\n",
    "    log_normalized_dataframe[\"z_score\"] = round((log_normalized_dataframe[\"initial_score\"] - log_normalized_dataframe[\"initial_score\"].mean()) / log_normalized_dataframe[\"initial_score\"].std(),2)\n",
    "    return log_normalized_dataframe.sort_values(by=\"z_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/course_excel_data_t1_2024/data_all_users.xlsx\"\n",
    "user_actions_dataframe = pd.read_excel(file_path, sheet_name=\"user_actions_data\").drop(columns=[\"posts_read\",\"topics_viewed\"])\n",
    "\n",
    "raw_scores_dataframe = create_raw_scores_dataframe_for_all_users(user_actions_dataframe)\n",
    "# log_normalized_scores_dataframe = create_log_normalized_scores_dataframe(raw_metrics_dataframe)\n",
    "\n",
    "# Use ExcelWriter in 'openpyxl' mode to append multiple sheets\n",
    "with pd.ExcelWriter(file_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"overlay\") as writer:\n",
    "    # raw_metrics_dataframe.to_excel(writer, sheet_name=\"raw_metrics\", index=False)\n",
    "    raw_scores_dataframe.to_excel(writer, sheet_name=\"unnormalized_scores\", index=False)\n",
    "    # log_normalized_scores_dataframe.to_excel(writer, sheet_name=\"log_normalized_scores\", index=False)\n",
    "    # We have not taken log normalized scores for all users as it is not required for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING/EXPLORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acting_username</th>\n",
       "      <th>created_new_topic</th>\n",
       "      <th>likes_given</th>\n",
       "      <th>likes_received</th>\n",
       "      <th>replied</th>\n",
       "      <th>solved_a_topic</th>\n",
       "      <th>initial_score</th>\n",
       "      <th>z_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teza</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>29.7</td>\n",
       "      <td>6.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23f2002361</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23f1000917</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23f3001021</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23f3003974</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  acting_username  created_new_topic  likes_given  likes_received  replied  \\\n",
       "0            teza                  0            0              10       21   \n",
       "1      23f2002361                  7            1               3        9   \n",
       "2      23f1000917                  2            2               6        8   \n",
       "3      23f3001021                  2            2               3        5   \n",
       "4      23f3003974                  1            3               3        2   \n",
       "\n",
       "   solved_a_topic  initial_score  z_score  \n",
       "0               7           29.7     6.64  \n",
       "1               0           12.5     2.52  \n",
       "2               0           12.0     2.40  \n",
       "3               1            8.5     1.57  \n",
       "4               0            5.2     0.78  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_excel(\"course_excel_data_t1_2024/English II.xlsx\", sheet_name=\"unnormalized_scores\").head()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acting_username</th>\n",
       "      <th>created_new_topic</th>\n",
       "      <th>likes_given</th>\n",
       "      <th>likes_received</th>\n",
       "      <th>replied</th>\n",
       "      <th>solved_a_topic</th>\n",
       "      <th>initial_score</th>\n",
       "      <th>z_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teza</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.398</td>\n",
       "      <td>3.091</td>\n",
       "      <td>2.079</td>\n",
       "      <td>7.568</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23f2002361</td>\n",
       "      <td>2.079</td>\n",
       "      <td>0.693</td>\n",
       "      <td>1.386</td>\n",
       "      <td>2.303</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.461</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23f1000917</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.946</td>\n",
       "      <td>2.197</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.341</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23f3001021</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.099</td>\n",
       "      <td>1.386</td>\n",
       "      <td>1.792</td>\n",
       "      <td>0.693</td>\n",
       "      <td>6.069</td>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23f3003974</td>\n",
       "      <td>0.693</td>\n",
       "      <td>1.386</td>\n",
       "      <td>1.386</td>\n",
       "      <td>1.099</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.564</td>\n",
       "      <td>-1.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  acting_username  created_new_topic  likes_given  likes_received  replied  \\\n",
       "0            teza              0.000        0.000           2.398    3.091   \n",
       "1      23f2002361              2.079        0.693           1.386    2.303   \n",
       "2      23f1000917              1.099        1.099           1.946    2.197   \n",
       "3      23f3001021              1.099        1.099           1.386    1.792   \n",
       "4      23f3003974              0.693        1.386           1.386    1.099   \n",
       "\n",
       "   solved_a_topic  initial_score  z_score  \n",
       "0           2.079          7.568     1.27  \n",
       "1           0.000          6.461     0.24  \n",
       "2           0.000          6.341     0.13  \n",
       "3           0.693          6.069    -0.12  \n",
       "4           0.000          4.564    -1.52  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create_log_normalized_scores_dataframe(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
